[
["methods.html", "5 Model methods 5.1 Display 5.2 Accessibility 5.3 Components 5.4 Interpolation 5.5 Re-estimation 5.6 Simulation 5.7 Visualisation", " 5 Model methods 5.1 Display The print and summary methods are standard displays for fitted models. The print method typically displays a limited amount of key information, such as the model that was fit, and the estimated coefficients. The summary function extends the print method with a more detailed summary of fit, which may include measures for goodness of fit, and significance of model terms. As fable naturally supports batch/multiple forecasting, the print method is standardised for any number of models. A very short model specific display can be defined using the model_sum generic, which is shown in the mable. library(tsibbledata) UKLungDeaths %&gt;% ETS(mdeaths) ## # A mable: 1 model [1M] ## data model ## &lt;list&gt; &lt;model&gt; ## 1 &lt;tsibble [72 × 3]&gt; ETS(M,A,A) The summary method can then be used to reveal more information about this model, such as fitted parameters and goodness of fit. Ideally this information would also be standardised into a tabular form for batch modelling, although this is currently not the case. UKLungDeaths %&gt;% ETS(mdeaths) %&gt;% summary ## ETS(M,A,A) ## ## Smoothing parameters: ## alpha = 0.0002065548 ## beta = 0.0001865257 ## gamma = 0.000118306 ## ## Initial states: ## l b s1 s2 s3 s4 s5 ## 1671.676 -4.334248 373.1746 -121.3157 -246.1697 -484.8581 -476.2192 ## s6 s7 s8 s9 s10 s11 s12 ## -370.1939 -303.5806 -207.384 122.0022 483.3319 620.3601 610.8525 ## ## ## sigma: 0.0951 ## ## AIC AICc BIC ## 1033.474 1044.807 1072.177 5.2 Accessibility augment(), tidy(), glance() 5.3 Components In many cases, a model can be used to extract features or components from data in a similar way to decomposition methods. We use the components verb to extract a tsibble of data features that have been extracted via modelling or decomposition. State space models such as ETS are well suited to this functionality as the states often represent features of interest. UKLungDeaths %&gt;% ETS(mdeaths) %&gt;% components ## # A tsibble: 73 x 4 [1M] ## index level slope season ## &lt;mth&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1974 Jan 1672. -4.33 373. ## 2 1974 Feb 1667. -4.36 611. ## 3 1974 Mar 1663. -4.44 620. ## 4 1974 Apr 1658. -4.49 483. ## 5 1974 May 1654. -4.47 122. ## 6 1974 Jun 1649. -4.46 -207. ## 7 1974 Jul 1645. -4.48 -304. ## 8 1974 Aug 1640. -4.48 -370. ## 9 1974 Sep 1636. -4.48 -476. ## 10 1974 Oct 1632. -4.47 -485. ## # ... with 63 more rows It may also be worth storing how these components can be used to produce the response, which can be used for decomposition modelling. 5.4 Interpolation Models that can be estimated in the presence of missing values can often be used to interpolate the unknown values. Often interpolated values can be taken from model’s fitted values, and some models may support more sophisticated interpolation methods. The forecast package provides the na.interp function for interpolating time series data, which uses linear interpolation for non-seasonal data, and STL decomposition for seasonal data. Tidy time series tools should allow users to interpolate missing values using any appropriate model. For example, the fpp2::mens400 dataset contains Olympic men’s 400m track final winning times. The winning times for the 1916, 1940 and 1944 Olympics are missing from the dataset. We could then interpolate these missing values using the fitted values from a linear model with a trend: as_tsibble(fpp2::mens400) %&gt;% LM(value ~ trend()) %&gt;% interpolate() ## # A tsibble: 31 x 2 [?] ## index value ## &lt;dttm&gt; &lt;dbl&gt; ## 1 1896-01-01 00:00:00 54.2 ## 2 1900-01-01 00:00:00 49.4 ## 3 1904-01-01 00:00:00 49.2 ## 4 1908-01-01 00:00:00 50 ## 5 1912-01-01 00:00:00 48.2 ## 6 1916-01-01 00:00:00 48.8 ## 7 1920-01-01 00:00:00 49.6 ## 8 1924-01-01 00:00:00 47.6 ## 9 1928-01-01 00:00:00 47.8 ## 10 1932-01-01 00:00:00 46.2 ## # ... with 21 more rows 5.5 Re-estimation https://github.com/tidyverts/fable/issues/43 5.5.1 refit() The refitting a model allows the same model to be applied to a new dataset. This is similar to the model argument available in most modelling functions from the forecast package. The refitted model should maintain the same structure and coefficients of the original model, with fitted information updated to reflect the model’s behaviour on the new dataset. It should also be possible to allow re-estimation of parameters using the reestimate argument, which keeps the selected model terms but updates the model coefficients/parameters. It is expected that a refit method uses a fitted model and replacement data to return a mable. For the ETS model for mdeaths estimated above: library(fable) ets_fit &lt;- as_tsibble(mdeaths) %&gt;% ETS(value) We may be interested in using the same model with the same coefficients to estimate the fdeaths series: refit(ets_fit, as_tsibble(fdeaths)) ## # A mable: 1 model [1M] ## data model ## &lt;list&gt; &lt;model&gt; ## 1 &lt;tsibble [72 × 2]&gt; ETS(M,A,A) 5.5.2 stream() Streaming data into a model allows a model to be extended to accomodate new, future data. Like refit, stream should allow re-estimation of the model parameters. As this can be a costly operation for some models, in most cases updating the parameters should not occur. However it is recommended that the model parameters are updated on a regular basis. Suppose we are estimating electricity demand data (tsibbledata::elecdemand), and after fitting a model to the existing data, a new set of data from the next month becomes available. A (minimal) model for the electricity demand above can be estimated using fasster. fit &lt;- elec_tr %&gt;% fasster(Demand ~ WorkDay %S% (poly(1) + trig(10))) To extend these fitted values to include December’s electricity data, we can use the stream functionality: fit &lt;- fit %&gt;% stream(elec_stream) 5.6 Simulation Much like the tidymodels opinion toward predict, simulate should not default to an archived version of the training set. This allows models to be used for simulating new data sets, which is especially relevant for time series as often future paths beyond the training set are simulated. The simulate method for a fable model should accept these arguments (names chosen for consistency with tidymodels): object: The model itself new_data: The data used for simulation times: The number of simulated series (handled by fablelite) seed: Random generator initialisation (handled by fablelite) The new_data dataset extends existing stats::simulate functionality by allowing the simulation to accept a new time index for simulating beyond the sample (.idx), and allows the simulation to work with a new set of exogenous regressors (say x1 and x2). It is expected that the innovations (.innov) for the simulation are randomly generated for each repition number (rep), which can be achieved using the times argument. However, users should also be able to provide a set of pre-generated innovations (.innov) for each repition (.rep). If these columns are provided in the new_data, then this data will be passed directly to the simulation method (without generating new numbers over times replications). ## # A tsibble: 9 x 5 [1M] ## # Key: .rep [3] ## .rep .idx .innov x1 x2 ## &lt;int&gt; &lt;mth&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2017 Jan 1.69 1.04 -2.36 ## 2 1 2017 Feb 1.20 0.457 -3.23 ## 3 1 2017 Mar -0.627 3.35 -2.18 ## 4 2 2017 Jan 1.35 -1.00 -2.27 ## 5 2 2017 Feb -1.27 -1.25 -2.86 ## 6 2 2017 Mar -1.04 4.60 -2.67 ## 7 3 2017 Jan 3.12 1.48 -2.24 ## 8 3 2017 Feb -1.44 3.12 -3.38 ## 9 3 2017 Mar -0.870 1.08 -4.89 For the end user, creating simulations would work like this: library(fable) library(tsibbledata) UKLungDeaths %&gt;% LM(mdeaths ~ fourier(&quot;year&quot;, K = 4) + fdeaths) %&gt;% simulate(UKLungDeaths, times = 5) ## # A tsibble: 360 x 3 [1M] ## # Key: .rep [5] ## index .rep .sim ## &lt;mth&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1974 Jan 1 2248. ## 2 1974 Feb 1 1666. ## 3 1974 Mar 1 2218. ## 4 1974 Apr 1 1872. ## 5 1974 May 1 1273. ## 6 1974 Jun 1 1078. ## 7 1974 Jul 1 1340. ## 8 1974 Aug 1 1073. ## 9 1974 Sep 1 1152. ## 10 1974 Oct 1 1573. ## # ... with 350 more rows Or, if they wanted to simulate beyond the sample: library(lubridate) UKLungDeaths %&gt;% filter(year(index) &lt;= 1978) %&gt;% LM(mdeaths ~ fourier(&quot;year&quot;, K = 4) + fdeaths) %&gt;% simulate( UKLungDeaths %&gt;% filter(year(index) &gt; 1978), times = 5 ) ## # A tsibble: 60 x 3 [1M] ## # Key: .rep [5] ## index .rep .sim ## &lt;mth&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1979 Jan 1 2122. ## 2 1979 Feb 1 2068. ## 3 1979 Mar 1 1883. ## 4 1979 Apr 1 1621. ## 5 1979 May 1 1257. ## 6 1979 Jun 1 1225. ## 7 1979 Jul 1 1229. ## 8 1979 Aug 1 1055. ## 9 1979 Sep 1 1026. ## 10 1979 Oct 1 1137. ## # ... with 50 more rows 5.7 Visualisation Different plots are appropriate for visualising each type of model. For example, a plot of an ARIMA model may show the AR and/or MA roots from the model on a unit circle. A linear model has several common plots, including plots showing “Residuals vs Fitted” values, normality via a Q-Q plot, and measures of leverage. These model plots are further extended by the visreg package to show the affects of terms on the model’s response. Some models currently have no model-specific plots, such as ETS, which defaults to showing a components plot using the estimated states. Visualising these models poses a substantial challenge for consistency across models, and is made more difficult as batch modelling becomes commonplace. "]
]
